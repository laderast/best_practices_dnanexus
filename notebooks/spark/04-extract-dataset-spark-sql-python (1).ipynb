{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Using Spark/pyspark to extract datasets from Apollo\n","\n","If our query is takes longer than 2 minutes to execute, `dx extract_datasets` will not run. In that case, we will start up a Spark instance of JupyterLab and run the SparkSQL directly in the notebook.\n","\n","1. Extract the relevant dictionary information\n","2. Connect to our Spark Cluster using `pyspark`\n","3. Extract the dataset SQL using the `--sql` option with `dx extract_dataset` and save output to a file\n","4. Load query from file, clean the SQL\n","5. Use `spark.sql` to load the dataset as a Spark DataFrame\n","6. Convert Spark DataFrame to Pandas\n","7. Use `.to_csv()` to save Pandas `DataFrame` as CSV file\n","8. Upload our CSV file back to project storage using `dx upload`."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Import Necessary Packages\n","\n","We'll need to import a number of Python packages, including `dxpy`. When in doubt, make sure to update to the latest version of `dxpy` using `pip install dxpy`."]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[],"source":["import subprocess\n","import dxpy\n","import pandas as pd\n","import os\n","import glob\n","pd.set_option('display.max_columns', None)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Use `dx extract_dataset` to extract Data Dictionary Files\n","\n","Now we'l extract the dictionary files using the `-ddd` option for `dx extract_dataset`."]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[],"source":["dataset = 'record-G5Ky4Gj08KQYQ4P810fJ8qPp'"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["cmd = [\"dx\", \"extract_dataset\", dataset, \"-ddd\", \"--delimiter\", \",\"]\n","subprocess.check_call(cmd)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["If we load up the data dictionary and the codings files, we'll be able to decode the categorical data."]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>entity</th>\n","      <th>name</th>\n","      <th>type</th>\n","      <th>primary_key_type</th>\n","      <th>coding_name</th>\n","      <th>concept</th>\n","      <th>description</th>\n","      <th>folder_path</th>\n","      <th>is_multi_select</th>\n","      <th>is_sparse_coding</th>\n","      <th>linkout</th>\n","      <th>longitudinal_axis_type</th>\n","      <th>referenced_entity_field</th>\n","      <th>relationship</th>\n","      <th>title</th>\n","      <th>units</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>participant</td>\n","      <td>p22608_a24</td>\n","      <td>integer</td>\n","      <td>NaN</td>\n","      <td>data_coding_493</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Online follow-up &gt; Work environment &gt; Employme...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>http://biobank.ctsu.ox.ac.uk/crystal/field.cgi...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Workplace very hot | Array 24</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>participant</td>\n","      <td>p2784_i1</td>\n","      <td>integer</td>\n","      <td>NaN</td>\n","      <td>data_coding_100349</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>UK Biobank Assessment Centre &gt; Touchscreen &gt; S...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>http://biobank.ctsu.ox.ac.uk/crystal/field.cgi...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Ever taken oral contraceptive pill | Instance 1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>participant</td>\n","      <td>p102780_i4</td>\n","      <td>integer</td>\n","      <td>NaN</td>\n","      <td>data_coding_100001</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Online follow-up &gt; Diet by 24-hour recall &gt; Br...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>http://biobank.ctsu.ox.ac.uk/crystal/field.cgi...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Other grain intake | Instance 4</td>\n","      <td>Serving</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>participant</td>\n","      <td>p41217</td>\n","      <td>integer</td>\n","      <td>NaN</td>\n","      <td>data_coding_228</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Health-related outcomes &gt; Hospital inpatient &gt;...</td>\n","      <td>yes</td>\n","      <td>NaN</td>\n","      <td>http://biobank.ctsu.ox.ac.uk/crystal/field.cgi...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Mental categories</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>participant</td>\n","      <td>p22704_a7</td>\n","      <td>integer</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Additional exposures &gt; Local environment &gt; Hom...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>http://biobank.ctsu.ox.ac.uk/crystal/field.cgi...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Home location - north co-ordinate (rounded) | ...</td>\n","      <td>metre-grid</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        entity        name     type primary_key_type         coding_name  \\\n","0  participant  p22608_a24  integer              NaN     data_coding_493   \n","1  participant    p2784_i1  integer              NaN  data_coding_100349   \n","2  participant  p102780_i4  integer              NaN  data_coding_100001   \n","3  participant      p41217  integer              NaN     data_coding_228   \n","4  participant   p22704_a7  integer              NaN                 NaN   \n","\n","   concept  description                                        folder_path  \\\n","0      NaN          NaN  Online follow-up > Work environment > Employme...   \n","1      NaN          NaN  UK Biobank Assessment Centre > Touchscreen > S...   \n","2      NaN          NaN  Online follow-up > Diet by 24-hour recall > Br...   \n","3      NaN          NaN  Health-related outcomes > Hospital inpatient >...   \n","4      NaN          NaN  Additional exposures > Local environment > Hom...   \n","\n","  is_multi_select is_sparse_coding  \\\n","0             NaN              NaN   \n","1             NaN              NaN   \n","2             NaN              NaN   \n","3             yes              NaN   \n","4             NaN              NaN   \n","\n","                                             linkout  longitudinal_axis_type  \\\n","0  http://biobank.ctsu.ox.ac.uk/crystal/field.cgi...                     NaN   \n","1  http://biobank.ctsu.ox.ac.uk/crystal/field.cgi...                     NaN   \n","2  http://biobank.ctsu.ox.ac.uk/crystal/field.cgi...                     NaN   \n","3  http://biobank.ctsu.ox.ac.uk/crystal/field.cgi...                     NaN   \n","4  http://biobank.ctsu.ox.ac.uk/crystal/field.cgi...                     NaN   \n","\n","  referenced_entity_field relationship  \\\n","0                     NaN          NaN   \n","1                     NaN          NaN   \n","2                     NaN          NaN   \n","3                     NaN          NaN   \n","4                     NaN          NaN   \n","\n","                                               title       units  \n","0                      Workplace very hot | Array 24         NaN  \n","1    Ever taken oral contraceptive pill | Instance 1         NaN  \n","2                    Other grain intake | Instance 4     Serving  \n","3                                  Mental categories         NaN  \n","4  Home location - north co-ordinate (rounded) | ...  metre-grid  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["path = os.getcwd()\n","\n","data_dict_csv = glob.glob(os.path.join(path, \"*.data_dictionary.csv\"))[0]\n","data_dict_df = pd.read_csv(data_dict_csv)\n","\n","codings_csv = glob.glob(os.path.join(path, \"*.codings.csv\"))[0]\n","codings_df = pd.read_csv(codings_csv)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Specify Field Names and Generate Spark SQL\n","\n","Here we specify the list of entity/field names as a list, and then use substitution to build our actual `dx extract_dataset` statement."]},{"cell_type":"code","execution_count":25,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["['participant.p31',\n"," 'participant.p21022',\n"," 'participant.p100240_i1',\n"," 'participant.eid']"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["entity_field2 = [\"participant.p31\", \"participant.p21022\", \"participant.p100240_i1\"]\n","entity_field2.append('participant.eid')\n","entity_field2"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Now we have our list of fields, we can now extract the Spark SQL using the `--sql` version.\n","\n","The SQL is returned as a text file, and we can specify its name using the `-o` option. Here we have called it `cohort.sql`."]},{"cell_type":"code","execution_count":26,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["0"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["cmd = [\"dx\", \"extract_dataset\", dataset, \"--fields\", ','.join(entity_field2), \n","       \"--sql\", \"-o\", \"cohort.sql\"]\n","\n","subprocess.check_call(cmd)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Connect to Spark \n","\n","Now we have the SparkSQL, we can execute it as a query on our dataset.\n","\n","Make sure you only run this code block once, as Spark doesn't like to be initialized twice. \n","\n","If you accidentally do that, use **Kernel > Restart Kernel** in the JupyterLab menu and start rerunning the code blocks from scratch."]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[],"source":["import pyspark\n","sc = pyspark.SparkContext()\n","spark = pyspark.sql.SparkSession(sc)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Load SQL and then retrieve as Spark DataFrame\n","\n","We now load our SQL from the file and clean it a little bit. \n","\n","Then we can run our query using `spark.sql()`. Running this returns a Spark DataFrame"]},{"cell_type":"code","execution_count":27,"metadata":{"trusted":true},"outputs":[],"source":["with open(\"cohort.sql\", \"r\") as file:\n","    retrieve_sql=\"\"\n","    for line in file: \n","        retrieve_sql += line.strip()\n","\n","\n","df = spark.sql(retrieve_sql.strip(\";\"))\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Convert to Pandas DataFrame\n","\n","Now we need to convert our Spark DataFrame to a Pandas one. We use the built in `.toPandas()` method to do this"]},{"cell_type":"code","execution_count":28,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>participant.p31</th>\n","      <th>participant.p21022</th>\n","      <th>participant.p100240_i1</th>\n","      <th>participant.eid</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>43</td>\n","      <td>1.0</td>\n","      <td>sample_100_116</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>60</td>\n","      <td>NaN</td>\n","      <td>sample_100_142</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>53</td>\n","      <td>0.0</td>\n","      <td>sample_100_285</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>62</td>\n","      <td>NaN</td>\n","      <td>sample_100_290</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>67</td>\n","      <td>NaN</td>\n","      <td>sample_100_304</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   participant.p31  participant.p21022  participant.p100240_i1 participant.eid\n","0                0                  43                     1.0  sample_100_116\n","1                0                  60                     NaN  sample_100_142\n","2                0                  53                     0.0  sample_100_285\n","3                0                  62                     NaN  sample_100_290\n","4                0                  67                     NaN  sample_100_304"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["df_pandas = df.toPandas()\n","df_pandas.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Save as CSV file in JupyterLab Storage"]},{"cell_type":"code","execution_count":29,"metadata":{"trusted":true},"outputs":[],"source":["df_pandas.to_csv(\"sql_output.csv\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Upload CSV files to Project"]},{"cell_type":"code","execution_count":31,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["ID                    file-GK7x6V80F5X8gxkp4v9qQXB6\n","Class                 file\n","Project               project-G3fz4600F5X7FkJz6qyZfb3g\n","Folder                /users/tladeras\n","Name                  cohort_data.csv\n","State                 closing\n","Visibility            visible\n","Types                 -\n","Properties            -\n","Tags                  -\n","Outgoing links        -\n","Created               Tue Dec  6 23:41:57 2022\n","Created by            tladeras\n"," via the job          job-GK7vJPQ0F5X7Y33Z4k4vkK39\n","Last modified         Tue Dec  6 23:41:57 2022\n","Media type            \n","archivalState         \"live\"\n","cloudAccount          \"cloudaccount-dnanexus\"\n","ID                    file-GK7x6VQ0F5XKpVb44yZPZbz5\n","Class                 file\n","Project               project-G3fz4600F5X7FkJz6qyZfb3g\n","Folder                /users/tladeras\n","Name                  extracted_data_with_code_meanings.csv\n","State                 closing\n","Visibility            visible\n","Types                 -\n","Properties            -\n","Tags                  -\n","Outgoing links        -\n","Created               Tue Dec  6 23:41:58 2022\n","Created by            tladeras\n"," via the job          job-GK7vJPQ0F5X7Y33Z4k4vkK39\n","Last modified         Tue Dec  6 23:41:58 2022\n","Media type            \n","archivalState         \"live\"\n","cloudAccount          \"cloudaccount-dnanexus\"\n","ID                    file-GK7x6VQ0F5X3XyYg4vK50bVq\n","Class                 file\n","Project               project-G3fz4600F5X7FkJz6qyZfb3g\n","Folder                /users/tladeras\n","Name                  extracted_data_with_sparse_code_drop.csv\n","State                 closing\n","Visibility            visible\n","Types                 -\n","Properties            -\n","Tags                  -\n","Outgoing links        -\n","Created               Tue Dec  6 23:41:58 2022\n","Created by            tladeras\n"," via the job          job-GK7vJPQ0F5X7Y33Z4k4vkK39\n","Last modified         Tue Dec  6 23:41:58 2022\n","Media type            \n","archivalState         \"live\"\n","cloudAccount          \"cloudaccount-dnanexus\"\n","ID                    file-GK7x6VQ0F5XBv6Bf4pzz0zBk\n","Class                 file\n","Project               project-G3fz4600F5X7FkJz6qyZfb3g\n","Folder                /users/tladeras\n","Name                  extracted_data_with_updated_titles.csv\n","State                 closing\n","Visibility            visible\n","Types                 -\n","Properties            -\n","Tags                  -\n","Outgoing links        -\n","Created               Tue Dec  6 23:41:58 2022\n","Created by            tladeras\n"," via the job          job-GK7vJPQ0F5X7Y33Z4k4vkK39\n","Last modified         Tue Dec  6 23:41:59 2022\n","Media type            \n","archivalState         \"live\"\n","cloudAccount          \"cloudaccount-dnanexus\"\n","ID                    file-GK7x6Vj0F5XJ6G724v448P9G\n","Class                 file\n","Project               project-G3fz4600F5X7FkJz6qyZfb3g\n","Folder                /users/tladeras\n","Name                  female_coffee_3.0.codings.csv\n","State                 closing\n","Visibility            visible\n","Types                 -\n","Properties            -\n","Tags                  -\n","Outgoing links        -\n","Created               Tue Dec  6 23:41:59 2022\n","Created by            tladeras\n"," via the job          job-GK7vJPQ0F5X7Y33Z4k4vkK39\n","Last modified         Tue Dec  6 23:41:59 2022\n","Media type            \n","archivalState         \"live\"\n","cloudAccount          \"cloudaccount-dnanexus\"\n","ID                    file-GK7x6Vj0F5X3g4fF4q36460x\n","Class                 file\n","Project               project-G3fz4600F5X7FkJz6qyZfb3g\n","Folder                /users/tladeras\n","Name                  female_coffee_3.0.data_dictionary.csv\n","State                 closing\n","Visibility            visible\n","Types                 -\n","Properties            -\n","Tags                  -\n","Outgoing links        -\n","Created               Tue Dec  6 23:41:59 2022\n","Created by            tladeras\n"," via the job          job-GK7vJPQ0F5X7Y33Z4k4vkK39\n","Last modified         Tue Dec  6 23:42:00 2022\n","Media type            \n","archivalState         \"live\"\n","cloudAccount          \"cloudaccount-dnanexus\"\n","ID                    file-GK7x6X00F5X8gxkp4v9qQXBB\n","Class                 file\n","Project               project-G3fz4600F5X7FkJz6qyZfb3g\n","Folder                /users/tladeras\n","Name                  female_coffee_3.0.entity_dictionary.csv\n","State                 closing\n","Visibility            visible\n","Types                 -\n","Properties            -\n","Tags                  -\n","Outgoing links        -\n","Created               Tue Dec  6 23:42:00 2022\n","Created by            tladeras\n"," via the job          job-GK7vJPQ0F5X7Y33Z4k4vkK39\n","Last modified         Tue Dec  6 23:42:00 2022\n","Media type            \n","archivalState         \"live\"\n","cloudAccount          \"cloudaccount-dnanexus\"\n","ID                    file-GK7x6X00F5X1FYf24qKfJjQ9\n","Class                 file\n","Project               project-G3fz4600F5X7FkJz6qyZfb3g\n","Folder                /users/tladeras\n","Name                  sql_output.csv\n","State                 closing\n","Visibility            visible\n","Types                 -\n","Properties            -\n","Tags                  -\n","Outgoing links        -\n","Created               Tue Dec  6 23:42:00 2022\n","Created by            tladeras\n"," via the job          job-GK7vJPQ0F5X7Y33Z4k4vkK39\n","Last modified         Tue Dec  6 23:42:01 2022\n","Media type            \n","archivalState         \"live\"\n","cloudAccount          \"cloudaccount-dnanexus\"\n"]}],"source":["%%bash\n","\n","dx upload *.csv --destination /users/tladeras/"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":4}
