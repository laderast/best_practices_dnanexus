{
  "hash": "ea6466ace442a1ae76d45556e7ce0924",
  "result": {
    "markdown": "---\ntitle: \"Hail on DNAnexus\"\n---\n\n## Learning Objectives\n\nAfter reading this chapter, you should be able to:\n\n  - **Explain** basic Hail terms and concepts\n  - **Import data** into a Hail MatrixTable from pVCF and BGEN formats\n  - **Merge** phenotypic data into the MatrixTable\n  - **QC** and **Filter** Variant data for use in a GWAS using Hail\n  - **QC** and **Filter** Sample data for use in GWAS with Hail\n  - **Run** GWAS on a Hail MatrixTable \n  - **Annotate** Hail MatrixTables with internal DNAnexus resources \n  - **Export** results from Hail to CSV format\n\n\n## What is Hail?\n\nHail is a genomics framework built on top of Spark to allow for scalable genomics queries. It uses many of the same concepts (partitions, executors, plans) but it is genomics focused. \n\nFor example, the Hail MatrixFrame can be QC'ed, and then filtered on these QC metrics.  \n\n## Vocabulary\n\nDNAnexus Specific:\n\n  - **DNAX** - S3 bucket for storing Apollo Databases and Tables - accessed with the `dnax://` protocol\n  - **Database Object** - data object on platform that represents a parquet database - has a unique identifier.\n\nHail Specific Terminology:\n\n  - **Spark Driver** - the \"boss\" of the Spark cluster - hosts the Spark UI\n  - **Spark Worker** - individual nodes that house executors\n  - **Hail Executor** - individual cores/CPUs within a worker - Executors are assigned tasks, identical to Spark.\n  - **Data Partition** - portion of the data that is accessed by worker in parquet columnar format\n  - **Key** - unique identifier for rows or columns\n\t- row keys: *rsid + alleles*\n\t- column keys: *sample IDs*\n\t\n## Very first thing: Connect to Hail\n\nThe first thing we'll do is connect to Hail. In our Spark DXJupyter Instance, we'll use the following boilerplate code:\n\n```\n# Running this cell will output a red-colored message- this is expected.\n# The 'Welcome to Hail' message in the output will indicate that Hail is ready to use in the notebook.\n\nfrom pyspark.sql import SparkSession\nimport hail as hl\n\nbuilder = (\n    SparkSession\n    .builder\n    .enableHiveSupport()\n)\nspark = builder.getOrCreate()\nhl.init(sc=spark.sparkContext)\n```\n\nThis will be the response from Hail:\n\n```\npip-installed Hail requires additional configuration options in Spark referring\n  to the path to the Hail Python module directory HAIL_DIR,\n  e.g. /path/to/python/site-packages/hail:\n    spark.jars=HAIL_DIR/hail-all-spark.jar\n    spark.driver.extraClassPath=HAIL_DIR/hail-all-spark.jar\n    spark.executor.extraClassPath=./hail-all-spark.jarRunning on Apache Spark version 2.4.4\nSparkUI available at http://ip-172-31-34-162.ec2.internal:8081\nWelcome to\n     __  __     <>__\n    / /_/ /__  __/ /\n   / __  / _ `/ / /\n  /_/ /_/\\_,_/_/_/   version 0.2.78-b17627756568\nLOGGING: writing to /opt/notebooks/hail-20230418-1956-0.2.78-b17627756568.log\n```\n\t\nNow we are ready to connect and do work with Hail.\n\nNote that you should only initialize one time in a notebook. If you try to initialize multiple times, then you will get an error.\n\nIf that happens, restart the notebook kernel (**Notebook** > **Restart Kernel** in the menu) and start executing all over again.\n\t\n## Important Data Structures in Hail: Tables and MatrixTables\n\nBefore we get started with doing a GWAS in Hail, let's talk about the data structures we'll work with. *Hail Tables* and *Hail MatrixTables*.\n\nOne of the hardest things to understand about Hail data structures is that they are actually linked data structures. It's easiest to think of them as data tables with attached metadata.\n\n## Hail Table\n\nThe fundamental data structure in Hail is the Hail Table.\n\nI think of Hail Tables as a regular data table with a set of metadata fields. These metadata fields are known as **global fields**. You can think of them as annotations for the entire table, such as the instrument used to generate the table, the software version used to process the data, etc.\n\nThere are multiple operations we can do on a Hail Table (let's call our Hail Table as `ht` here):\n\n- `ht.filter()`\n- `ht.annotate()`\n- `ht.show()` \n\nLet's look at some examples of these operations. We can find a list of the row fields for table using `.describe()`:\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nht.describe()\n```\n:::\n\n\nAs we work with MatrixTables, we'll see that it is actually a little conceptually easier to filter on our sample QC data, then join it back to the MatrixTable to filter out samples that don't meet our criteria. \n\n## Hail MatrixTable\n\nIn contrast, Hail MatrixTables consist of the entries (genotypes) that have metadata attached to both the rows and columns. (They also have global fields, but let's ignore that for now.)\n\nThe main data structure is the table itself, which contains the genotypes. This table is considered as the **entry fields**. Each entry (or cell) contains data.\n\nFor example, if we call\n\n```\nmt.GT.show()\n```\n\nIt will show the first few rows and columns of the genotypes (the example shown is synthetic data):\n\n![](images/entry_fields.png)\n\nWe call the row metadata **row fields**, which correspond to the genomic variants in the MatrixTable. *Operations on the row fields are operations on genomic variants.* (technically the data in a Hail Table are also called row fields, but I find this to be confusing).\n\nHere's an example of some row fields. We'll see that the rows correspond to variants, and the columns correspond to metrics or annotations about the variants.\n\n![](images/row_fields.png)\n\nWe call the column metadata **column fields**, which correspond to the samples in the MatrixTable. The rows in this table correspond to samples in our MatrixTable, and the columns correspond to per sample covariates (such as gender, age). \n\nHere's an example of some column fields.\n\n![](images/column_fields.png)\n\nPutting everything together, we see this:\n\n![](images/mt_all.png) \n\n## Keep in Mind\n\nThe cardinal rule of MatrixTables is this:\n\n> **Row** operations operate on *variants*, while **Column** operations operate on *samples*.\n\nIt is easy to get lost in a chain of Hail commands and not be able to understand what the code is doing unless you concentrate on this.\n\n![](images/keep_in_mind.png)\n\n:::{.callout-note}\n## Storing MatrixTables in DNAX\n\nIn general, if you are loading from pVCF files, we suggest that you save the MatrixTable into DNAX. This is because loading pVCF files is an expensive operation compared to BGEN files.\n\nHowever, we suggest doing filtering and QC of your variants before you save your MatrixTable to DNAX. In general, you will be doubly charged for MatrixTable storage along with your pVCF file storage if you store without filtering, so it is worth reducing the data stored in DNAX.\n\nNote that BGEN files can be directly loaded from Project Storage, but if there is a large amount of filtering/preprocessing involved, it is also worth storing the results as a MatrixTable in DNAX for others to use/access downstream. \n:::\n\n## \n\n",
    "supporting": [
      "14-hail-on-dnanexus_files/figure-pdf"
    ],
    "filters": []
  }
}